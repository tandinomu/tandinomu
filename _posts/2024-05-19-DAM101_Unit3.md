---
Title: DAM101 Journal 3
categories: [DAM101, Jornal 3]
tags: [DAM101]
---

## Unit 3: Convolutional Neural Network 
--- 

A Convolutional Neural Network (CNN) is a type of artificial neural network used primarily for image recognition and processing, due to its ability to recognize patterns in images. It is widely used for tasks like image recognition, object detection, and facial recognition.

In the context of CNN, ***convolution*** is a mathematical operation that combines two functions to produce a third function expressing how the shape of one is modified by the other. This operation is performed by applying a set of weights, known as a filter or kernel, to the input data. The filter slides across the input data, performing a dot product between the filter values and the corresponding input values to produce a feature map.

![cnn](/assets/img/cnnm.webp)

This process highlights the presence and location of specific features within the input data.

The convolution operation in CNNs is designed to capture local dependencies in the input data, which is particularly useful for image processing where spatial relationships matter. By sliding the filter across the input data, the network can detect features regardless of their position in the image, achieving a form of translation invariance. This means the network can recognize features even if they appear in different positions or orientations within the image.

In summary, convolution in CNNs is a powerful mechanism for extracting and learning features from input data, enabling the network to perform complex tasks such as image classification, object detection, and more. 

CNNs are structured with several types of layers, including:

- Convolutional layers: Where the primary computation happens. Filters are applied to the input data to extract features.

- Pooling layers: Reduce the spatial dimensions of the input volume, decreasing computational complexity and reducing overfitting.

- Fully connected layers: Perform the final classification or regression task after the feature maps have been extracted and processed through the preceding layers.

The core component of a CNN is the convolutional layer, which applies filters (also known as kernels) to the input data to extract features. This is the layer where CNNs automatically learn and identify patterns within the data, making them highly effective for tasks that involve recognizing complex structures within images or videos.

![layersofcnn](/assets/img/layersofcnn.png)

### Kernals

A filter, or kernel, in a CNN is a small matrix of weights that slides over the input data such as an image. It performs element-wise multiplication with the part of the input it is currently on, and then sums up all the results into a single output pixel.

#### Types of Kernels:

**Size**: 

Kernels come in various sizes, with common dimensions being 3x3, 5x5, and 7x7. The choice of kernel size affects the level of detail captured and computational efficiency. Larger kernels capture more detailed information but require more computational resources, whereas smaller kernels are quicker but they may miss finer details. 

Different kernels can be applied in Convolutional Neural Networks (CNNs) for various effects on an image:

**Sharpen Kernel**: Enhances edges and details, useful for clarity in tasks like image recognition.

**Left and Right Sobel Kernels**: Detect vertical edges, aiding in tasks such as object detection.

**Gaussian Blur Kernel**: Reduces noise and smoothens images, commonly used before processing for tasks like image classification.

The following elements are interconnected in how they affect the size and depth of feature maps in CNNs:

**Input Channels**: This refers to the number of channels in the input data. In the context of images, it's usually three for RGB images (red, green, and blue channels). 

**Feature Maps**: Feature maps are the output of applying filters (kernels) to the input data. Each filter produces one feature map. The number of feature maps corresponds to the number of filters used in a convolutional layer.

**Number of Kernels**: This refers to the number of filters used in a convolutional layer. Each filter is convolved with the input to produce a feature map. The number of kernels determines the depth of the output volume.

**Stride**: Stride determines how much the filter (kernel) moves across the input data. A larger stride means the filter skips over more pixels at each step, resulting in a smaller output size.

**Padding**: Padding is adding extra pixels around the input data. It's often used to preserve the spatial dimensions of the input when applying convolution operations. Padding helps in preventing information loss at the edges of the image.

**Depth**: Depth refers to the number of feature maps produced by a convolutional layer. It's determined by the number of kernels used in that layer.

### Pooling 


